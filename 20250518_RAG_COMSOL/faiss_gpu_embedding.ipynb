{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e133227-d2ce-41bf-9ce9-121d4792d527",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/venvs/faissgpu/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:01<00:00,  4.55it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import faiss\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "assert hasattr(faiss, \"StandardGpuResources\"), \"Still using CPU-only FAISS\"\n",
    "\n",
    "# === CONFIG ===\n",
    "MODEL_NAME = \"Alibaba-NLP/gte-Qwen2-7B-instruct\"\n",
    "BATCH_SIZE = 64\n",
    "CHUNK_SIZE = 512\n",
    "# EMBED_DIM = 4096  # Depends on model\n",
    "EMBED_DIM = 3584  # Updated to match actual embedding dimension\n",
    "DEVICE_COUNT = torch.cuda.device_count()\n",
    "\n",
    "# === Load model/tokenizer on all devices ===\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModel.from_pretrained(MODEL_NAME, torch_dtype=torch.float16).half().eval()\n",
    "\n",
    "# === Read and chunk your documents ===\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "with open(\"extracted_texts.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    texts = f.read().split(\"=== Document \")[1:]\n",
    "    texts = [doc.split(\"\\n\", 1)[1] for doc in texts]\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=100)\n",
    "documents = [chunk for text in texts for chunk in splitter.split_text(text)]\n",
    "\n",
    "# === Embed with batching on one GPU (parallelize later) ===\n",
    "def embed_batch(batch_texts):\n",
    "    inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=CHUNK_SIZE)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)  # Ensure model is on same device\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "        # Mean pooling over sequence (dimension 1)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "        return embeddings.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e59ebeab-9a9c-42b5-a166-710d7ee7b70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding: 100%|██████████| 1788/1788 [12:37<00:00,  2.36it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === Loop over batches and embed ===\n",
    "all_embeddings = []\n",
    "for i in tqdm(range(0, len(documents), BATCH_SIZE), desc=\"Embedding\"):\n",
    "    batch = documents[i:i + BATCH_SIZE]\n",
    "    batch_texts = [doc for doc in batch]\n",
    "    emb = embed_batch(batch_texts)\n",
    "    all_embeddings.append(emb)\n",
    "\n",
    "all_embeddings = np.vstack(all_embeddings).astype(\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6730b985-f12e-4125-9f66-48850ecc37d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Build FAISS GPU index ===\n",
    "res = faiss.StandardGpuResources()\n",
    "index = faiss.IndexFlatL2(EMBED_DIM)\n",
    "gpu_index = faiss.index_cpu_to_gpu(res, 0, index)  # Use GPU 0 or loop over all\n",
    "\n",
    "gpu_index.add(all_embeddings)\n",
    "\n",
    "# === Save index and docs ===\n",
    "faiss.write_index(faiss.index_gpu_to_cpu(gpu_index), \"faiss_index.index\")\n",
    "np.save(\"documents.npy\", np.array(documents, dtype=object))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c30cf2b-1747-4c48-8326-c601332edf17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.7583008 ,  0.4428711 , -1.4121094 , ...,  0.18249512,\n",
       "        -3.0039062 ,  0.08831787],\n",
       "       [-0.4086914 ,  0.35913086, -3.3945312 , ...,  3.5664062 ,\n",
       "        -3.3984375 , -0.05462646],\n",
       "       [-0.48291016,  0.7138672 , -3.2285156 , ..., -0.15551758,\n",
       "        -2.1640625 ,  2.2597656 ],\n",
       "       ...,\n",
       "       [ 0.1583252 ,  0.30493164, -2.5136719 , ...,  2.546875  ,\n",
       "        -2.1894531 ,  3.5664062 ],\n",
       "       [ 1.6416016 ,  3.7597656 , -3.28125   , ...,  4.2148438 ,\n",
       "        -1.7158203 ,  4.046875  ],\n",
       "       [-3.9335938 , -1.7763672 , -0.6088867 , ...,  3.5683594 ,\n",
       "        -2.3320312 ,  1.8359375 ]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b3312c-3416-4c11-bee3-cabae5682e20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (faissgpu)",
   "language": "python",
   "name": "faissgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
